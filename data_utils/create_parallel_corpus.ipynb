{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from xml.etree import cElementTree as ET\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "import scipy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'superuser.com'\n",
    "directory = os.path.join('data', 'superuser.com')\n",
    "x = ET.parse(os.path.join(directory, 'Posts.xml'))\n",
    "root = x.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question(child):\n",
    "    if child.attrib['PostTypeId'] == '1':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_question_for_answer(child):\n",
    "    return child.attrib['ParentId']\n",
    "\n",
    "def may_get_attrib(child, attribute):\n",
    "    if attribute in child.attrib:\n",
    "        return child.attrib[attribute]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def clean_punctuation(s):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    cleantext = s.translate(translator)\n",
    "    return cleantext\n",
    "\n",
    "def tokenize(s):\n",
    "    s = s.strip()\n",
    "    s = clean_html(s)\n",
    "    s = clean_punctuation(s)\n",
    "    string_split = s.strip().split()\n",
    "    ret = map(lambda x: x.lower(), string_split)\n",
    "    return list(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {}\n",
    "answer_dict = {}\n",
    "num_retrieval = float('Inf')\n",
    "\n",
    "for idx, child in enumerate(root):\n",
    "    if idx < num_retrieval:\n",
    "        if is_question(child):\n",
    "            query_id = int(child.attrib['Id'])\n",
    "            query_dict[query_id] = {'Body': may_get_attrib(child, 'Body')}\n",
    "            query_dict[query_id]['Title'] = may_get_attrib(child, 'Title')\n",
    "            query_dict[query_id]['AcceptedAnswerId'] = may_get_attrib(child, 'AcceptedAnswerId')\n",
    "            query_dict[query_id]['Tokens'] = tokenize(query_dict[query_id]['Body'])\n",
    "            query_dict[query_id]['Tokens_title'] = tokenize(query_dict[query_id]['Title'])\n",
    "\n",
    "        else:\n",
    "            answer_id = int(child.attrib['Id'])\n",
    "            answer_dict[answer_id] = {'Body': may_get_attrib(child, 'Body')}\n",
    "            answer_dict[answer_id]['ParentId'] = may_get_attrib(child, 'ParentId')\n",
    "            answer_dict[answer_id]['Score'] = may_get_attrib(child, 'Score')\n",
    "            answer_dict[answer_id]['Tokens'] = tokenize(answer_dict[answer_id]['Body'])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390593 training samples\n"
     ]
    }
   ],
   "source": [
    "parallel = []\n",
    "parallel_query = []\n",
    "for _, answer in answer_dict.items():\n",
    "    if not answer['ParentId']:\n",
    "        continue\n",
    "    q_id = int(answer['ParentId'])\n",
    "    q = query_dict[q_id]['Tokens_title']\n",
    "    d = answer['Tokens']\n",
    "    qd_pair = (\" \".join(q), \" \".join(d))\n",
    "    parallel.append(qd_pair)\n",
    "\n",
    "for _, query in query_dict.items():\n",
    "    q = query['Tokens_title']\n",
    "    d = query['Tokens']\n",
    "    qd_pair = (\" \".join(q), \" \".join(d))\n",
    "    parallel_query.append(qd_pair)\n",
    "print(\"{} training samples\".format(len(parallel_query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "parallel_corpus = parallel_query\n",
    "data_dir = os.path.join(\"seq2seq_data\", data_source)\n",
    "sp.check_output(\"mkdir -p {}_qd\".format(data_dir), shell=True)\n",
    "doc = os.linesep.join(map(lambda x: x[1], parallel_corpus))\n",
    "query = os.linesep.join(map(lambda x: x[0], parallel_corpus))\n",
    "\n",
    "with open(os.path.join(data_dir, \"text.query\"), \"w\") as f:\n",
    "    f.write(query)\n",
    "with open(os.path.join(data_dir, \"text.doc\"), \"w\") as f:\n",
    "    f.write(doc)\n",
    "\n",
    "num_dev = 5000\n",
    "doc_train = os.linesep.join(map(lambda x: x[1], parallel_corpus[:-num_dev]))\n",
    "doc_dev = os.linesep.join(map(lambda x: x[1], parallel_corpus[-num_dev:]))\n",
    "query_train = os.linesep.join(map(lambda x: x[0], parallel_corpus[:-num_dev]))\n",
    "query_dev = os.linesep.join(map(lambda x: x[0], parallel_corpus[-num_dev:]))\n",
    "\n",
    "with open(os.path.join(data_dir, \"train.text.query\"), \"w\") as f:\n",
    "    f.write(query_train)\n",
    "with open(os.path.join(data_dir, \"train.text.doc\"), \"w\") as f:\n",
    "    f.write(doc_train)\n",
    "with open(os.path.join(data_dir, \"dev.text.query\"), \"w\") as f:\n",
    "    f.write(query_dev)\n",
    "with open(os.path.join(data_dir, \"dev.text.doc\"), \"w\") as f:\n",
    "    f.write(doc_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_corpus = parallel\n",
    "data_dir = os.path.join(\"seq2seq_data\", data_source)\n",
    "sp.check_output(\"mkdir -p {}_qa\".format(data_dir), shell=True)\n",
    "doc = os.linesep.join(map(lambda x: x[1], parallel_corpus))\n",
    "query = os.linesep.join(map(lambda x: x[0], parallel_corpus))\n",
    "\n",
    "with open(os.path.join(data_dir, \"text.query\"), \"w\") as f:\n",
    "    f.write(query)\n",
    "with open(os.path.join(data_dir, \"text.doc\"), \"w\") as f:\n",
    "    f.write(doc)\n",
    "\n",
    "num_dev = 5000\n",
    "doc_train = os.linesep.join(map(lambda x: x[1], parallel_corpus[:-num_dev]))\n",
    "doc_dev = os.linesep.join(map(lambda x: x[1], parallel_corpus[-num_dev:]))\n",
    "query_train = os.linesep.join(map(lambda x: x[0], parallel_corpus[:-num_dev]))\n",
    "query_dev = os.linesep.join(map(lambda x: x[0], parallel_corpus[-num_dev:]))\n",
    "\n",
    "with open(os.path.join(data_dir, \"train.text.query\"), \"w\") as f:\n",
    "    f.write(query_train)\n",
    "with open(os.path.join(data_dir, \"train.text.doc\"), \"w\") as f:\n",
    "    f.write(doc_train)\n",
    "with open(os.path.join(data_dir, \"dev.text.query\"), \"w\") as f:\n",
    "    f.write(query_dev)\n",
    "with open(os.path.join(data_dir, \"dev.text.doc\"), \"w\") as f:\n",
    "    f.write(doc_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
